{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autotime"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n","time: 6.7 s\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from autoPyTorch import (AutoNetClassification)\n","import pandas as pd\n","import numpy as np\n","import os as os\n","import json\n","from sklearn.metrics import accuracy_score\n","\n","train = pd.read_csv('D:/Data/fashion-mnist/data/archive/fashion-mnist_train.csv')\n","test = pd.read_csv('D:/Data/fashion-mnist/data/archive/fashion-mnist_test.csv')\n","X = train.drop(columns=['label'],axis=1)\n","y = train.label\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17, test_size=0.2)\n","\n","autoPyTorch = AutoNetClassification(\"tiny_cs\",  # config preset\n","                                   log_level='debug',\n","                                    use_tensorboard_logger=True,\n","                                    #save_models=True !gives error!\n","                                    cross_validator='k_fold',\n","                                    cuda=True,\n","                                    full_eval_each_epoch = True,\n","                                    validation_split=0.2,\n","                                    budget_type='epochs',\n","                                    result_logger_dir='Experiment_logs/Zalando/',\n","                                    random_seed=17,\n","                                    max_runtime=300,\n","                                    min_budget=1,\n","                                    max_budget=10)"]},{"cell_type":"code","execution_count":3,"metadata":{"tags":["outputPrepend"]},"outputs":[{"output_type":"stream","name":"stderr","text":[":57 Finished train with budget 0.12345679012345678: Preprocessing took 10s, Training took 39s, Wrap up took 0s. Total time consumption in s: 50\n","22:45:57 [AutoNet] Done with current split!\n","22:45:57 [AutoNet] CV split 19 of 20\n","22:45:57 Fit: Imputation\n","22:46:03 Fit: NormalizationStrategySelector\n","22:46:05 Fit: OneHotEncoding\n","22:46:05 Fit: PreprocessorSelector\n","22:46:09 Fit: ResamplingStrategySelector\n","22:46:09 Fit: EmbeddingSelector\n","22:46:09 Fit: NetworkSelector\n","22:46:09 Fit: InitializationSelector\n","22:46:09 Fit: OptimizerSelector\n","22:46:09 Fit: LearningrateSchedulerSelector\n","22:46:09 Fit: LogFunctionsSelector\n","22:46:09 Fit: MetricSelector\n","22:46:09 Fit: LossModuleSelector\n","22:46:09 Fit: CreateDataLoader\n","22:46:09 Fit: TrainNode\n","22:46:09 Start train. Budget: 0.12345679012345678\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","22:46:30 Perform learning rate scheduling\n","22:46:30 Budget used: 0/0.12345679012345678\n","22:46:30 Epoch: 0 : {'loss': 0.4934561522779884, 'model_parameters': 7767364, 'train_accuracy': 83.2021978021978, 'val_accuracy': 86.08333333333333, 'lr_scheduler_converged': False, 'lr': 0.05601834309632739}\n","22:46:51 Perform learning rate scheduling\n","22:46:51 Budget used: 1/0.12345679012345678\n","22:46:51 Budget exhausted!\n","22:46:51 Epoch: 1 : {'loss': 0.445425051008607, 'model_parameters': 7767364, 'train_accuracy': 85.71208791208791, 'val_accuracy': 85.16666666666667, 'lr_scheduler_converged': False, 'lr': 0.05601834309632739}\n","22:46:51 Finished train with budget 0.12345679012345678: Preprocessing took 12s, Training took 41s, Wrap up took 0s. Total time consumption in s: 53\n","22:46:51 [AutoNet] Done with current split!\n","22:46:51 Aggregate the results across the splits\n","22:46:51 Process 20 additional result(s)\n","22:46:51 Send additional results {} to master\n","22:46:51 Result: -85.06874999999998 info: {'loss': 0.44779911272145895, 'model_parameters': 7767364.0, 'train_accuracy': 85.6456043956044, 'val_accuracy': 85.06875, 'lr_scheduler_converged': 0.0, 'lr': 0.056018343096327396}\n","22:46:51 Training ['shapedresnet'] with budget 2.4691358024691357 resulted in optimize-metric-loss: -85.06874999999998 took 964.4250597953796 seconds\n","22:46:51 WORKER: done with job (0, 0, 11), trying to register it.\n","22:46:51 WORKER: registered result for job (0, 0, 11) with dispatcher\n","22:46:51 DISPATCHER: job (0, 0, 11) finished\n","22:46:51 DISPATCHER: register_result: lock acquired\n","22:46:51 DISPATCHER: job (0, 0, 11) on hpbandster.run_0.worker.LAPTOP-4Q2U8M99.23556.-139296 finished\n","22:46:51 job_id: (0, 0, 11)\n","kwargs: {'config': {'CreateDataLoader:batch_size': 125, 'Imputation:strategy': 'median', 'InitializationSelector:initialization_method': 'default', 'InitializationSelector:initializer:initialize_bias': 'No', 'LearningrateSchedulerSelector:lr_scheduler': 'cosine_annealing', 'LossModuleSelector:loss_module': 'cross_entropy_weighted', 'NetworkSelector:network': 'shapedresnet', 'NormalizationStrategySelector:normalization_strategy': 'standardize', 'OptimizerSelector:optimizer': 'sgd', 'PreprocessorSelector:preprocessor': 'truncated_svd', 'ResamplingStrategySelector:over_sampling_method': 'none', 'ResamplingStrategySelector:target_size_strategy': 'none', 'ResamplingStrategySelector:under_sampling_method': 'none', 'TrainNode:batch_loss_computation_technique': 'standard', 'LearningrateSchedulerSelector:cosine_annealing:T_max': 10, 'LearningrateSchedulerSelector:cosine_annealing:eta_min': 2, 'NetworkSelector:shapedresnet:activation': 'relu', 'NetworkSelector:shapedresnet:blocks_per_group': 4, 'NetworkSelector:shapedresnet:max_units': 346, 'NetworkSelector:shapedresnet:num_groups': 8, 'NetworkSelector:shapedresnet:resnet_shape': 'brick', 'NetworkSelector:shapedresnet:use_dropout': 0, 'NetworkSelector:shapedresnet:use_shake_drop': 0, 'NetworkSelector:shapedresnet:use_shake_shake': 0, 'OptimizerSelector:sgd:learning_rate': 0.05601834309632739, 'OptimizerSelector:sgd:momentum': 0.34615806043308806, 'OptimizerSelector:sgd:weight_decay': 0.023645748826996122, 'PreprocessorSelector:truncated_svd:target_dim': 100}, 'budget': 2.4691358024691357, 'working_directory': '.'}\n","result: {'loss': -85.06874999999998, 'info': {'loss': 0.44779911272145895, 'model_parameters': 7767364.0, 'train_accuracy': 85.6456043956044, 'val_accuracy': 85.06875, 'lr_scheduler_converged': 0.0, 'lr': 0.056018343096327396}}\n","exception: None\n","\n","22:46:51 job_callback for (0, 0, 11) started\n","22:46:51 DISPATCHER: Trying to submit another job.\n","22:46:51 job_callback for (0, 0, 11) got condition\n","22:46:51 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n","22:46:51 Only 12 run(s) for budget 2.469136 available, need more than 30 -> can't build model!\n","22:46:51 HBMASTER: Trying to run another job!\n","22:46:51 job_callback for (0, 0, 11) finished\n","22:46:51 HBMASTER: Timelimit reached: wait for remaining 0 jobs\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 ITERATION: Advancing config (0, 0, 0) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 1) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 2) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 3) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 4) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 5) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 6) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 7) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 8) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 9) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 10) to next budget 7.407407\n","22:46:51 ITERATION: Advancing config (0, 0, 11) to next budget 7.407407\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:51 start sampling a new configuration.\n","22:46:51 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 start sampling a new configuration.\n","22:46:52 done sampling a new configuration.\n","22:46:52 HBMASTER: Canceled 109 remaining runs\n","22:46:52 HBMASTER: shutdown initiated, shutdown_workers = True\n","22:46:52 WORKER: shutting down now!\n","22:46:52 DISPATCHER: Dispatcher shutting down\n","22:46:52 DISPATCHER: discover_workers shutting down\n","22:46:52 DISPATCHER: 'discover_worker' thread exited\n","22:46:52 DISPATCHER: Trying to submit another job.\n","22:46:52 DISPATCHER: job_runner shutting down\n","22:46:52 DISPATCHER: 'job_runner' thread exited\n","22:46:52 DISPATCHER: shut down complete\n","22:46:52 Fit: AutoNetSettings\n","22:46:52 Start autonet with config:\n","{'embeddings': ['none'], 'lr_scheduler': ['cosine_annealing'], 'networks': ['shapedresnet'], 'preprocessors': ['truncated_svd'], 'target_size_strategies': ['none'], 'over_sampling_methods': ['none'], 'under_sampling_methods': ['none'], 'batch_loss_computation_techniques': ['standard'], 'imputation_strategies': ['median'], 'initialization_methods': ['default'], 'loss_modules': ['cross_entropy_weighted'], 'normalization_strategies': ['standardize'], 'optimizer': ['sgd'], 'hyperparameter_search_space_updates': <autoPyTorch.utils.hyperparameter_search_space_update.HyperparameterSearchSpaceUpdates object at 0x000001A5C1ADB2B0>, 'log_level': 'debug', 'use_tensorboard_logger': True, 'cross_validator': 'k_fold', 'cuda': True, 'full_eval_each_epoch': True, 'validation_split': 0.2, 'budget_type': 'epochs', 'result_logger_dir': 'Experiment_logs/Zalando/', 'random_seed': 17, 'max_runtime': 7000, 'min_budget': 1, 'max_budget': 200, 'cross_validator_args': {'n_splits': 20}, 'num_iterations': 10, 'categorical_features': None, 'dataset_name': None, 'run_id': '0', 'task_id': -1, 'algorithm': 'bohb', 'portfolio_type': 'greedy', 'eta': 3, 'min_workers': 1, 'working_dir': '.', 'network_interface_name': '{64376B25-5D38-49A9-8097-72CB5E88AA24}', 'memory_limit_mb': 1000000, 'run_worker_on_master_node': True, 'use_pynisher': True, 'refit_validation_split': 0.0, 'min_budget_for_cv': 0, 'shuffle': True, 'final_activation': 'softmax', 'initializer': 'simple_initializer', 'additional_logs': [], 'optimize_metric': 'accuracy', 'additional_metrics': [], 'torch_num_threads': 1, 'best_over_epochs': False, 'save_models': False, 'predict_model': None, 'early_stopping_patience': inf, 'early_stopping_reset_parameters': False, 'cv_splits': 1, 'increase_number_of_trained_datasets': False}\n","22:46:52 Fit: CreateDatasetInfo\n","22:46:52 Fit: OptimizationAlgorithm\n","22:46:52 Start Refitting\n","22:46:52 Fit: CrossValidation\n","22:46:52 Validation split is set to 0 and cross validator specified, autonet will ignore validation split\n","22:46:52 [Autonet] No cross validation when refitting! Continue by splitting 0 of training data.\n","22:46:52 Took 0.08499884605407715 s to initialize optimization.\n","22:46:52 [AutoNet] CV split 0 of 1\n","22:46:53 Fit: Imputation\n","22:46:59 Fit: NormalizationStrategySelector\n","22:47:01 Fit: OneHotEncoding\n","22:47:01 Fit: PreprocessorSelector\n","22:47:05 Fit: ResamplingStrategySelector\n","22:47:05 Fit: EmbeddingSelector\n","22:47:05 Fit: NetworkSelector\n","22:47:05 Fit: InitializationSelector\n","22:47:05 Fit: OptimizerSelector\n","22:47:05 Fit: LearningrateSchedulerSelector\n","22:47:05 Fit: LogFunctionsSelector\n","22:47:05 Fit: MetricSelector\n","22:47:05 Fit: LossModuleSelector\n","22:47:05 Fit: CreateDataLoader\n","22:47:05 Fit: TrainNode\n","22:47:05 Start train. Budget: 0.12345679012345678\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","22:47:26 Perform learning rate scheduling\n","22:47:26 Budget used: 0/0.12345679012345678\n","22:47:26 Epoch: 0 : {'loss': 0.4880490303427602, 'model_parameters': 7767364, 'train_accuracy': 83.47291666666666, 'lr_scheduler_converged': False, 'lr': 0.05601834309632739}\n","22:47:47 Perform learning rate scheduling\n","22:47:47 Budget used: 1/0.12345679012345678\n","22:47:47 Budget exhausted!\n","22:47:47 Epoch: 1 : {'loss': 0.4530160129070282, 'model_parameters': 7767364, 'train_accuracy': 85.48958333333333, 'lr_scheduler_converged': False, 'lr': 0.05601834309632739}\n","22:47:47 Finished train with budget 0.12345679012345678: Preprocessing took 12s, Training took 41s, Wrap up took 0s. Total time consumption in s: 54\n","22:47:47 [AutoNet] Done with current split!\n","22:47:47 Aggregate the results across the splits\n","22:47:47 Process 1 additional result(s)\n","22:47:47 Send additional results {} to master\n","22:47:47 Done Refitting\n"]},{"output_type":"execute_result","data":{"text/plain":["{'optimized_hyperparameter_config': {'CreateDataLoader:batch_size': 125,\n","  'Imputation:strategy': 'median',\n","  'InitializationSelector:initialization_method': 'default',\n","  'InitializationSelector:initializer:initialize_bias': 'No',\n","  'LearningrateSchedulerSelector:lr_scheduler': 'cosine_annealing',\n","  'LossModuleSelector:loss_module': 'cross_entropy_weighted',\n","  'NetworkSelector:network': 'shapedresnet',\n","  'NormalizationStrategySelector:normalization_strategy': 'standardize',\n","  'OptimizerSelector:optimizer': 'sgd',\n","  'PreprocessorSelector:preprocessor': 'truncated_svd',\n","  'ResamplingStrategySelector:over_sampling_method': 'none',\n","  'ResamplingStrategySelector:target_size_strategy': 'none',\n","  'ResamplingStrategySelector:under_sampling_method': 'none',\n","  'TrainNode:batch_loss_computation_technique': 'standard',\n","  'LearningrateSchedulerSelector:cosine_annealing:T_max': 10,\n","  'LearningrateSchedulerSelector:cosine_annealing:eta_min': 2,\n","  'NetworkSelector:shapedresnet:activation': 'relu',\n","  'NetworkSelector:shapedresnet:blocks_per_group': 4,\n","  'NetworkSelector:shapedresnet:max_units': 346,\n","  'NetworkSelector:shapedresnet:num_groups': 8,\n","  'NetworkSelector:shapedresnet:resnet_shape': 'brick',\n","  'NetworkSelector:shapedresnet:use_dropout': 0,\n","  'NetworkSelector:shapedresnet:use_shake_drop': 0,\n","  'NetworkSelector:shapedresnet:use_shake_shake': 0,\n","  'OptimizerSelector:sgd:learning_rate': 0.05601834309632739,\n","  'OptimizerSelector:sgd:momentum': 0.34615806043308806,\n","  'OptimizerSelector:sgd:weight_decay': 0.023645748826996122,\n","  'PreprocessorSelector:truncated_svd:target_dim': 100},\n"," 'budget': 2.4691358024691357,\n"," 'loss': -85.06874999999998,\n"," 'info': {'loss': 0.44779911272145895,\n","  'model_parameters': 7767364.0,\n","  'train_accuracy': 85.6456043956044,\n","  'val_accuracy': 85.06875,\n","  'lr_scheduler_converged': 0.0,\n","  'lr': 0.056018343096327396}}"]},"metadata":{},"execution_count":3},{"output_type":"stream","name":"stdout","text":["time: 2h 10min 29s\n"]}],"source":["autoPyTorch.fit(X_train, y_train, cross_validator_args={\"n_splits\": 20}, num_iterations=10, max_runtime=7000, max_budget=200)\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy score 0.8581666666666666\ntime: 4.18 s\n"]}],"source":["import sklearn.model_selection\n","import sklearn.datasets\n","import sklearn.metrics\n","\n","y_pred = autoPyTorch.predict(X_test)\n","print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, y_pred))\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"output_type":"stream","name":"stderr","text":["23:36:28 Fit: AutoNetSettings\n","23:36:28 Start autonet with config:\n","{'embeddings': ['none'], 'lr_scheduler': ['cosine_annealing'], 'networks': ['shapedresnet'], 'preprocessors': ['truncated_svd'], 'target_size_strategies': ['none'], 'over_sampling_methods': ['none'], 'under_sampling_methods': ['none'], 'batch_loss_computation_techniques': ['standard'], 'imputation_strategies': ['median'], 'initialization_methods': ['default'], 'loss_modules': ['cross_entropy_weighted'], 'normalization_strategies': ['standardize'], 'optimizer': ['sgd'], 'hyperparameter_search_space_updates': <autoPyTorch.utils.hyperparameter_search_space_update.HyperparameterSearchSpaceUpdates object at 0x000001A5F7759978>, 'log_level': 'debug', 'use_tensorboard_logger': True, 'cross_validator': 'k_fold', 'cuda': True, 'full_eval_each_epoch': True, 'validation_split': 0.2, 'budget_type': 'epochs', 'result_logger_dir': 'Experiment_logs/Zalando/', 'random_seed': 17, 'max_runtime': 7000, 'min_budget': 1, 'max_budget': 200, 'cross_validator_args': {'n_splits': 20}, 'num_iterations': 10, 'categorical_features': None, 'dataset_name': None, 'run_id': '0', 'task_id': -1, 'algorithm': 'bohb', 'portfolio_type': 'greedy', 'eta': 3, 'min_workers': 1, 'working_dir': '.', 'network_interface_name': '{64376B25-5D38-49A9-8097-72CB5E88AA24}', 'memory_limit_mb': 1000000, 'run_worker_on_master_node': True, 'use_pynisher': True, 'refit_validation_split': 0.0, 'min_budget_for_cv': 0, 'shuffle': True, 'final_activation': 'softmax', 'initializer': 'simple_initializer', 'additional_logs': [], 'optimize_metric': 'accuracy', 'additional_metrics': [], 'torch_num_threads': 1, 'best_over_epochs': False, 'save_models': False, 'predict_model': None, 'early_stopping_patience': inf, 'early_stopping_reset_parameters': False, 'cv_splits': 1, 'increase_number_of_trained_datasets': False}\n","23:36:28 Fit: CreateDatasetInfo\n","23:36:29 Fit: OptimizationAlgorithm\n","23:36:29 Start Refitting\n","23:36:30 Fit: CrossValidation\n","23:36:30 Validation split is set to 0 and cross validator specified, autonet will ignore validation split\n","23:36:30 [Autonet] No cross validation when refitting! Continue by splitting 0 of training data.\n","23:36:30 Took 0.09999918937683105 s to initialize optimization.\n","23:36:30 [AutoNet] CV split 0 of 1\n","23:36:30 Fit: Imputation\n","23:36:45 Fit: NormalizationStrategySelector\n","23:36:50 Fit: OneHotEncoding\n","23:36:50 Fit: PreprocessorSelector\n","23:37:02 Fit: ResamplingStrategySelector\n","23:37:02 Fit: EmbeddingSelector\n","23:37:02 Fit: NetworkSelector\n","23:37:02 Fit: InitializationSelector\n","23:37:02 Fit: OptimizerSelector\n","23:37:02 Fit: LearningrateSchedulerSelector\n","23:37:02 Fit: LogFunctionsSelector\n","23:37:02 Fit: MetricSelector\n","23:37:02 Fit: LossModuleSelector\n","23:37:02 Fit: CreateDataLoader\n","23:37:02 Fit: TrainNode\n","23:37:02 Start train. Budget: 0.12345679012345678\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:509: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","D:\\miniconda3\\envs\\pynew\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","23:38:09 Perform learning rate scheduling\n","23:38:09 Budget used: 0/0.12345679012345678\n","23:38:09 Epoch: 0 : {'loss': 0.4765093501036366, 'model_parameters': 7767364, 'train_accuracy': 83.97166666666666, 'lr_scheduler_converged': False, 'lr': 0.05601834309632739}\n","23:39:16 Perform learning rate scheduling\n","23:39:16 Budget used: 1/0.12345679012345678\n","23:39:16 Budget exhausted!\n","23:39:16 Epoch: 1 : {'loss': 0.4720347210764885, 'model_parameters': 7767364, 'train_accuracy': 85.425, 'lr_scheduler_converged': False, 'lr': 0.05601834309632739}\n","23:39:16 Finished train with budget 0.12345679012345678: Preprocessing took 32s, Training took 134s, Wrap up took 0s. Total time consumption in s: 166\n","23:39:16 [AutoNet] Done with current split!\n","23:39:16 Aggregate the results across the splits\n","23:39:16 Process 1 additional result(s)\n","23:39:16 Send additional results {} to master\n","23:39:16 Done Refitting\n","time: 2min 48s\n"]}],"source":["results_refit = autoPyTorch.refit(X,\n","                              y,\n","                              autonet_config=autoPyTorch.get_current_autonet_config(),\n","                              )"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n  (0): Linear(in_features=100, out_features=346, bias=True)\n  (1): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (2): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (3): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (4): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (5): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (6): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (7): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (8): Sequential(\n    (0): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (1): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (2): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n    (3): ResBlock(\n      (layers): Sequential(\n        (0): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (1): ReLU()\n        (2): Linear(in_features=346, out_features=346, bias=True)\n        (3): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (4): ReLU()\n        (5): Linear(in_features=346, out_features=346, bias=True)\n      )\n    )\n  )\n  (9): BatchNorm1d(346, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU()\n  (11): Linear(in_features=346, out_features=10, bias=True)\n)\ntime: 43.7 ms\n"]}],"source":["\n","with open(\"Experiment_logs/Zalando/results_refit.json\", \"w\") as file:\n","    json.dump(results_refit, file)\n","\n","zalando_model = autoPyTorch.get_pytorch_model()\n","print(zalando_model)    "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["time: 1.59 s\n"]}],"source":["import pickle\n","\n","with open('Experiment_logs/Zalando/zalando.pickle', 'wb') as f:\n","    pickle.dump(zalando_model, f)\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}